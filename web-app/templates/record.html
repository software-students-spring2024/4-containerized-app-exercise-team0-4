{% extends "layout.html" %} {% block content %}
<div>
  <h1 style="font-size: 24px;">Record Memo</h1>
</div>

<div class="audio-recorder">
  <div class="controls" style="display: flex;">
    <div id="startButton" class="button" style="margin-right: 10px;"><button>Start</button></div>
    <div id="stopButton" class="button" style="margin-right: 10px;"><button>Stop</button></div>
    <div id="saveButton" class="button"><button>Save</button></div>
  </div>
  <div class="audio-preview">
    <audio id="preview" width="160" height="120" autoplay muted></audio>
  </div>
  <div class="audio-recording">
    <audio id="recording" width="160" height="120" controls></audio>
  </div>
  <div class="log">
    <pre id="log"></pre>
  </div>
</div>

<script>
  let preview = document.getElementById("preview");
  let recording = document.getElementById("recording");
  let startButton = document.getElementById("startButton");
  let stopButton = document.getElementById("stopButton");
  let logElement = document.getElementById("log");
  let recordedBlob;

  let recordingTimeMS = 1000; // 1 second minimum of audio

  function log(msg) {
    logElement.innerHTML += `${msg}\n`;
  }

  function wait(delayInMS) {
    return new Promise((resolve) => setTimeout(resolve, delayInMS));
  }

  function startRecording(stream, lengthInMS) {
    let recorder = new MediaRecorder(stream);
    let data = [];

    recorder.ondataavailable = (event) => data.push(event.data);
    recorder.start();
    log(`Recording; click Stop to end`);

    let stopped = new Promise((resolve, reject) => {
      track = preview.srcObject.getTracks()[0];
      while (track.readyState === "ended") {
        recorder.stop(); // stop recording after user hits stop
        break;
      }
      recorder.onstop = resolve;
      recorder.onerror = (event) => reject(event.name);
    });
    let recorded = wait(lengthInMS).then(() => {});

    return Promise.all([stopped, recorded]).then(() => data);
  }

  function stop(stream) {
    stream.getTracks().forEach((track) => track.stop());
  }

  function save() {
    console.log(recordedBlob)
    fetch("http://127.0.0.1:3001/upload-audio", {
      method: "POST",
      headers: {
        "Content-Type": "audio/mpeg"
      },
      body: recordedBlob
    })
    .then(response => response.json())
    .then(data => {
      // Uploaded
      console.log("Uploaded");
      // WAIT UNTIL ML CLIENT RETURNS TRANSCRIPT
      log(`Retrieving audio transcript.`);
      // DISPLAY TRANSCRIPT
      console.log(data.message)
      log(`Transcript: ` + data.transcript)
    })
    .catch((error) => {
      console.log(error);
    });
    log(`Successfully saved audio.`);
  }

  startButton.addEventListener(
    "click",
    () => {
      navigator.mediaDevices
        .getUserMedia({
          audio: true,
        })
        .then((stream) => {
          preview.srcObject = stream;
          preview.captureStream =
            preview.captureStream || preview.mozCaptureStream;
          return new Promise((resolve) => (preview.onplaying = resolve));
        })
        .then(() => startRecording(preview.captureStream(), recordingTimeMS))
        .then((recordedChunks) => {
          recordedBlob = new Blob(recordedChunks, { type: "audio/mpeg" });
          console.log(recordedBlob);
          recording.src = URL.createObjectURL(recordedBlob);

          log(
            `Successfully recorded ${recordedBlob.size} bytes of ${recordedBlob.type} media.`
          );
        })
        .catch((error) => {
          if (error.name === "NotFoundError") {
            log("Microphone not found. Can't record.");
          } else {
            log(error);
          }
        });
    },
    false
  );

  stopButton.addEventListener(
    "click",
    () => {
      stop(preview.srcObject);
    },
    false
  );
  saveButton.addEventListener(
    "click",
    () => {
      save();
    },
    false
  );
</script>
{% endblock %}